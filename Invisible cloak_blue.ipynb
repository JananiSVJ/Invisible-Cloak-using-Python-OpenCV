{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps to perform initially in Anaconda prompt\n",
    "# conda create -n cvenv python=3.8 (create an environment \"cvenv\")\n",
    "# conda activate cvenv (activate the environment)\n",
    "# pip install opencv-python (install opencv)\n",
    "# jupyter notebook (open jupyter notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - 1 - Import librarires\n",
    "# cv2 library - image and video processing library (opencv - open source computer vision library)\n",
    "# Numpy library - supports large multi-dimensional array for scientific computing (Numpy - Numerical Python)  \n",
    "\n",
    "import cv2 \n",
    "import time\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Capture the video through webcam\n",
    "\n",
    "# FourCC is a 4-byte code used to specify the video file type (ex: XVID, MJPG, DIVX)\n",
    "# fps - frame rate - how many frames do you want to display per second in your video\n",
    "# iscolor - whether or not we are writing color frames to the file\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out_vid = cv2.VideoWriter('output.avi',fourcc,20.0, (640,480),True)  # videowriter(\"filename\",fourcc,fps,framesize,iscolor)\n",
    "\n",
    "# Create a video capture object which is helpful to capture videos through webcam\n",
    "# index passed is the id of the video capturing device to open. To open default camera using default backend just pass 0\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# system sleeps for 3 seconds before the webcam starts\n",
    "time.sleep(3)\n",
    "count = 0\n",
    "frame = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the frame/background\n",
    "for i in range(60):\n",
    "     ret,frame = capture.read()  # ret = 1 if the video is captured; frame is the background image\n",
    "frame = np.flip(frame,1) # flipcode > 0 - flips the image horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Tracking\n",
    "# 1. Take each frame of the video\n",
    "# 2. Convert from BGR to HSV color-space (we can use this to extract a colored object. \n",
    "#                                         In HSV, it is more easier to represent a color than RGB color-space.)\n",
    "# 3. We threshold the HSV image for a range of blue color (or any chosen color)\n",
    "# 4. Now extract the blue object alone, we can do whatever on that image we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each frame from webcam when the camera is open \n",
    "while(capture.isOpened()):\n",
    "    ret,image = capture.read()  # ret = 1 if the video is captured; image is the frame captured by webcam\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    image = np.flip(image, axis=1)\n",
    "    # Color conversion from BGR to HSV \n",
    "    hsv_frame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # H-Hue, S-Saturation, V-Value/brightness\n",
    "    \n",
    "     \n",
    "    low_blue1 = np.array([80, 50, 20])\n",
    "    upper_blue1 = np.array([100, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv_frame, low_blue1, upper_blue1) # Threshold the HSV image to get only blue colors\n",
    "    \n",
    "\n",
    "    lower_blue2 = np.array([100,50,20])\n",
    "    upper_blue2 = np.array([135,255,255])\n",
    "    mask2 = cv2.inRange(hsv_frame,lower_blue2,upper_blue2)  # Threshold the HSV image to get only blue colors\n",
    "    mask1 = mask1 + mask2 # '+' means 'or' here , any blue shade as in mask 1 or mask 2 will be segmented and stored in mask 1\n",
    "    \n",
    "    # Removes noise in the image\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    mask1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, kernel) \n",
    "    \n",
    "    mask1 = cv2.morphologyEx(mask1, cv2.MORPH_DILATE, kernel)\n",
    "    \n",
    "    # Create an inverted mask to segment out the blue color from the frame\n",
    "    mask2 = cv2.bitwise_not(mask1)\n",
    "   \n",
    "    # Segment the blue color part out of the frame using bitwise and with the inverted mask\n",
    "    result1 = cv2.bitwise_and(image,image,mask=mask2)\n",
    "   \n",
    "    # Create image showing static background frame pixels only for the masked region\n",
    "    result2 = cv2.bitwise_and(frame, frame, mask = mask1)\n",
    "    \n",
    "    # Using opencv, you can add or blend two images with the help of cv2.addWeighted() method.\n",
    "    finalOutput = cv2.addWeighted(result1,1,result2,1,0)\n",
    "    out_vid.write(finalOutput)\n",
    "    cv2.imshow(\"Invisible_magic\",finalOutput)\n",
    "    cv2.waitKey(1)\n",
    "cap.release()\n",
    "out_vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
